FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000001490116120000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000000000000020000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=3 31 3 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (3, 5, 1.00000000000000000000e+000) (0, 5, 1.00000000000000000000e+000) (31, 0, 1.00000000000000000000e+000) (31, 0, 1.00000000000000000000e+000) (0, 0, 1.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 1.43369187999585250000e+000) (1, 8.74475070356421250000e-001) (2, 1.57763023655924540000e-001) (0, -1.50000000000000000000e+003) (1, 1.50000000000000000000e+003) (2, 1.50000000000000000000e+003) (0, -6.61399868446001070000e-001) (1, 2.47036475444153640000e+000) (2, -1.60032390333575750000e-001) (0, -6.73591686448458460000e-001) (1, -7.59610955111777120000e-001) (2, 1.17454469602866720000e+000) (0, 7.30473629398118660000e-001) (1, -9.91167817462666580000e-001) (2, -1.44197381701616390000e-001) (0, -2.54119700703970830000e-001) (1, -2.63001606483519890000e-001) (2, -5.67797400668307750000e-001) (0, 6.96977691575510040000e-001) (1, -2.96395960148970290000e+000) (2, 4.02276498022470540000e+000) (0, 7.45112981332083150000e-001) (1, -5.43893215480374730000e-001) (2, -1.29790515562421160000e+000) (0, -6.49117801453906050000e-002) (1, 1.66813288875858220000e+000) (2, 2.63099200634612410000e+000) (0, -1.49226483542931080000e+003) (1, 1.50000000000000000000e+003) (2, 1.50000000000000000000e+003) (0, 1.70190300725100300000e-001) (1, 2.54164085733233150000e+000) (2, 2.42596683365765160000e+000) (0, -5.40295502046733930000e-001) (1, -5.71246039382148570000e-001) (2, -9.50021509869398370000e-001) (0, -1.20905458431761120000e-001) (1, 1.92710592569341550000e+000) (2, 8.42238920579251870000e-001) (0, -4.97978529443695530000e-003) (1, 3.97614563984264890000e+000) (2, 6.38543881737519750000e-001) (0, 9.77715592820055380000e-001) (1, -1.16809276360380210000e+000) (2, -2.13554482702825730000e+000) (0, 3.72678449832627030000e+000) (1, 4.96617996395859570000e-001) (2, 4.22036975350873430000e+000) (0, 4.59348546506648340000e+000) (1, 4.18994434559534220000e+000) (2, 9.70005090344703000000e-002) (0, 4.43501959980366340000e-001) (1, 1.59002388580552930000e+000) (2, -1.62271451348516370000e+000) (0, 2.13609330701161810000e-001) (1, 1.74292796194250000000e+000) (2, -8.07808535369980430000e-001) (0, 1.20906403011700680000e+000) (1, -8.73640088468818800000e-001) (2, 8.66292955222503940000e-001) (0, -1.23543415651305110000e+000) (1, 7.43187948294240510000e-001) (2, -2.29771976073456200000e-001) (0, 1.08356256059220610000e+000) (1, 2.89990448868747520000e+000) (2, -4.78193195713983170000e-001) (0, 2.36733250808664810000e+000) (1, 1.18719522237512480000e+000) (2, 3.26832681818604450000e-002) (0, 3.67121843290398080000e+000) (1, -2.71552206054553490000e-001) (2, 4.26590296801163490000e+000) (0, -1.40975670453955600000e+000) (1, -2.04733300847739440000e+000) (2, 3.15232586492743700000e+000) (0, -3.57251247755484290000e+000) (1, -1.00496128193555070000e+000) (2, 4.53039273911755560000e+000) (0, -3.42290360284284220000e-001) (1, 3.09467616734816750000e+000) (2, 1.19627854456549330000e+000) (0, -1.32583094420365950000e+000) (1, 1.81173654825181140000e-001) (2, 8.53809073008029770000e-001) (0, 1.18032324322189010000e+002) (1, 1.50000000000000000000e+003) (2, 1.50000000000000000000e+003) (0, 1.44163387683234870000e+000) (1, 2.53771570423868440000e-001) (2, 7.04144703853373240000e-001) (3, 3.06234028822298980000e+000) (4, 4.98972217437888390000e-001) (5, 1.98242008706403650000e+000) (6, 7.72388096537091770000e+000) (7, 5.61475830771949360000e+000) (8, 4.10938240693255620000e+000) (9, 1.65895176084921550000e+000) (10, 4.54156524134766660000e+000) (11, 4.35993276596647840000e+000) (12, -8.40712523682458080000e-001) (13, 2.86139663109530940000e+000) (14, 7.88515173040714860000e+000) (15, 2.43198632781346950000e+000) (16, 1.19480862255008270000e+000) (17, 5.81422923278496920000e+000) (18, 9.50038646213266610000e-001) (19, -1.23778133020796720000e-001) (20, 3.67775807655543870000e+000) (21, 1.89608583154949970000e+000) (22, 2.89108822808368650000e+000) (23, 3.15207251538060880000e+000) (24, -7.41809290426340360000e-001) (25, -1.59028337840864320000e+000) (26, 6.23375527938955560000e-001) (27, -6.65182572635144240000e-001) (28, 1.85314922907495650000e+000) (29, 2.18482717109998250000e+000) (30, 2.13959257417974810000e-001) (31, 8.85972978795261600000e-001) (32, 1.28443187858415770000e-001) (33, -1.16877165308086720000e+000) (3, -1.70179050040512390000e+000) (4, -3.41212130322343930000e-001) (5, 2.08908747352266970000e+000) (6, 3.57281992964377350000e+000) (7, 7.54516479663115010000e+000) (8, 4.57938550507739790000e+000) (9, 4.98519827082340060000e+000) (10, 4.35943873927841090000e+000) (11, 3.91923362959327500000e+000) (12, -1.57535158076376280000e+000) (13, 5.16449932400467220000e+000) (14, 5.95189473933142120000e+000) (15, -1.93808795700815480000e+000) (16, 2.09757881921868750000e+000) (17, 7.63792087477107720000e+000) (18, -1.75137392954003370000e+000) (19, -7.06578678867815500000e-002) (20, 2.20410620631163700000e+000) (21, 3.19370020248637590000e+000) (22, 1.44256498302707730000e-001) (23, 2.24585341612726750000e-001) (24, -8.00354797951234210000e-001) (25, 2.42675548333679350000e-001) (26, 5.16911428283664430000e+000) (27, 6.26018528785813210000e-001) (28, 2.90647757626811920000e+000) (29, 2.84514551406868190000e+000) (30, 3.36236396446135370000e+000) (31, -2.39784979043538950000e+000) (32, 2.42434960808150460000e+000) (33, -1.25586745548556310000e+000) 
